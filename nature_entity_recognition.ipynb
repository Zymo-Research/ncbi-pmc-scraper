{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import openai\n",
    "import tiktoken\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from Nature.NatureScraper import NatureScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = NatureScraper()\n",
    "links = scraper.get_article_links(\"microbiomics\")\n",
    "scraper.close_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.get_url(links[0])\n",
    "input(\"Enter credentials manually on Chromium, then press Enter to continue...\")\n",
    "articles = scraper.get_full_articles(links)\n",
    "scraper.close_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_dict = dict(zip(links, articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert Product Recognition system.\n",
    "Your task is to analyze a given text and accurately identify and extract all of the mentioned products.\n",
    "If a product's brand is specified, ensure to include the brand name along with the product.\n",
    "Here is an example of the output format for a list of strings.\n",
    "\n",
    "Text: I started my day with a fresh cup of coffee (Folgers) brewed from my coffee maker (Keurig), and then I prepared breakfast using my new KitchenAid stand mixer. After breakfast, I grabbed my running shoes (Nike) and went for a jog in the park. On my way back, I stopped by the store to pick up a pack of Tide laundry detergent and a bottle of Coca-Cola. After getting home, I started working on my laptop, which runs on a Microsoft operating system.\n",
    "Answer: [\"Folgers coffee\", \"Keurig coffee maker\", \"KitchenAid stand mixer\", \"Nike running shoes\", \"Tide laundry detergent\", \"Coca-Cola\", \"Laptop\", \"Microsoft operating system\"]\n",
    "\n",
    "Only use this output format. Do not return anything besides this output format.\n",
    "Return all of the mentioned products in the order they occur in the input text.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"Q: Given the text below, identify and extract all mentioned products.\n",
    "\n",
    "Text: {}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_recognition(input_text):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        presence_penalty=0,\n",
    "        top_p=1e-16,\n",
    "        temperature=1e-16,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt.format(input_text)}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_lengths = len(enc.encode(user_prompt)) + len(enc.encode(system_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, max_tokens, prefix_length, model_name):\n",
    "    max_len = max_tokens - prefix_length\n",
    "    sentences = sent_tokenize(text)\n",
    "    encoder = tiktoken.encoding_for_model(model_name)\n",
    "    total_length = 0\n",
    "    chunk_list = []\n",
    "    current_chunk = []\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(encoder.encode(sentence))\n",
    "        total_length += sentence_length\n",
    "        if total_length >= max_len:\n",
    "            total_length = 0\n",
    "            chunk_list.append(\" \".join(current_chunk))\n",
    "            current_chunk.clear()\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "    if current_chunk:\n",
    "        chunk_list.append(\" \".join(current_chunk))\n",
    "    return chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dict = {}\n",
    "for k, v in method_dict.items():\n",
    "    method_len = len(enc.encode(v))\n",
    "    if method_len > 2000 - prefix_lengths:\n",
    "        chunks = split_text(v, 2000, prefix_lengths, 'gpt-4-turbo')\n",
    "        all_entities = []\n",
    "        for chunk in chunks:\n",
    "            entities = product_recognition(chunk)\n",
    "            all_entities.extend(ast.literal_eval(entities))\n",
    "        product_dict[k] = all_entities\n",
    "    else:\n",
    "        entities = product_recognition(v)\n",
    "        product_dict[k] = ast.literal_eval(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-turbo\n",
    "for k, v in product_dict.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
